{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, task, plane, train=True, transform=None, weights=None):\n",
    "        super().__init__()\n",
    "        self.task = task\n",
    "        self.plane = plane\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.fold_path = self.root_dir + 'train/{}/'.format(plane)\n",
    "            self.records = pd.read_csv(self.root_dir + 'train-{}.csv'.format(task), header=None, names=['id', 'label'])\n",
    "        else:\n",
    "            transform = None\n",
    "            self.fold_path = self.root_dir + 'valid/{}/'.format(plane)\n",
    "            self.records = pd.read_csv(self.root_dir + 'valid-{}.csv'.format(task), header=None, names=['id', 'label'])\n",
    "            \n",
    "        self.records['id'] = self.records['id'].map(lambda i: '0'*(4 - len(str(i))) + str(i))\n",
    "        self.paths = [self.fold_path + filename + '.npy' for filename in self.records['id'].tolist()]\n",
    "        self.labels = self.records['label'].tolist()\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        if weights is None:\n",
    "            pos = np.sum(self.labels)\n",
    "            neg = len(self.labels) - pos\n",
    "            self.weights = torch.FloatTensor([1, neg/pos])\n",
    "        else:\n",
    "            self.weights = torch.FloatTensor(weights)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        array = np.load(self.paths[index])\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if label == 1:\n",
    "            label = torch.FloatTensor([0, 1])\n",
    "        elif label == 0:\n",
    "            label = torch.FloatTensor([1, 0])\n",
    "            \n",
    "        if self.transform:\n",
    "            array = self.transform(array)\n",
    "        else:\n",
    "            array = np.stack((array, )*3, axis=1)\n",
    "            array = torch.FloatTensor(array)\n",
    "            \n",
    "#         if label.item() == 1:\n",
    "#             weight = np.array([self.weights[1]])\n",
    "#             weight = torch.FloatTensor(weight)\n",
    "#         else:\n",
    "#             weight = np.array([self.weights[0]])\n",
    "#             weight = torch.FloatTensor(weight)\n",
    "            \n",
    "        return array, label, self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained_model = models.alexnet(pretrained=True)\n",
    "        self.pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifer = nn.Linear(256, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x, dim=0)\n",
    "        features = self.pretrained_model.features(x)\n",
    "        pooled_features = self.pooling_layer(features)\n",
    "        pooled_features = pooled_features.view(pooled_features.size(0), -1)\n",
    "        flattened_features = torch.max(pooled_features, 0, keepdim=True)[0]\n",
    "        output = self.classifer(flattened_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Coronal plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epoch, num_epochs, optimizer, current_lr):\n",
    "    model.train()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        \n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    losses = []\n",
    "    \n",
    "    for i, (image, label, weight) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image, label, weight = image.cuda(), label.cuda(), weight.cuda()\n",
    "            \n",
    "#         label = label[0]\n",
    "        weight = weight[0]\n",
    "        \n",
    "        prediction = model.forward(image.float())\n",
    "        \n",
    "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "        probas = torch.sigmoid(prediction)\n",
    "        \n",
    "        y_trues.append(int(label[0][1]))\n",
    "        y_preds.append(probas[0][1].item())\n",
    "        \n",
    "        try:\n",
    "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
    "        except:\n",
    "            auc = 0.5\n",
    "            \n",
    "        if (i % 100 == 0) & (i > 0):\n",
    "            print('Epoch: {} / {} | Single batch number : {} / {} | avg train loss : {} | train auc : {} | lr : {}'.format(\n",
    "            epoch+1, num_epochs, i, len(train_loader), np.round(np.mean(losses), 4), np.round(auc, 4), current_lr\n",
    "            ))\n",
    "            \n",
    "    train_loss_epoch = np.round(np.mean(losses), 4)\n",
    "    train_auc_epoch = np.round(auc, 4)\n",
    "    return train_loss_epoch, train_auc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_loader, epoch, num_epochs, current_lr):\n",
    "    model.eval()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        \n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    losses = []\n",
    "    \n",
    "    for i, (image, label, weight) in enumerate(valid_loader):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image, label, weight = image.cuda(), label.cuda(), weight.cuda()\n",
    "            \n",
    "#         label = label[0]\n",
    "        weight = weight[0]\n",
    "        \n",
    "        prediction = model(image.float())\n",
    "        \n",
    "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "        probas = torch.sigmoid(prediction)\n",
    "        \n",
    "        y_trues.append(int(label[0][1]))\n",
    "        y_preds.append(probas[0][1].item())\n",
    "        \n",
    "        try:\n",
    "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
    "        except:\n",
    "            auc = 0.5\n",
    "            \n",
    "        if (i % 20 == 0) & (i > 0):\n",
    "            print('Epoch: {} / {} | Single batch number : {} / {} | avg val loss : {} | val auc : {} | lr : {}'.format(\n",
    "            epoch+1, num_epochs, i, len(valid_loader), np.round(np.mean(losses), 4), np.round(auc, 4), current_lr\n",
    "            ))\n",
    "            \n",
    "    val_loss_epoch = np.round(np.mean(losses), 4)\n",
    "    val_auc_epoch = np.round(auc, 4)\n",
    "    return val_loss_epoch, val_auc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Coronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " augmentor = Compose([\n",
    "        transforms.Lambda(lambda x: torch.Tensor(x)),\n",
    "        RandomRotate(25),\n",
    "        RandomTranslate([0.11, 0.11]),\n",
    "        RandomFlip(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1, 1).permute(1, 0, 2, 3)),\n",
    "    ])\n",
    "\n",
    "coronal_train_dataset = MRDataset(root_dir='', task='acl', plane='coronal', transform=augmentor, train=True)\n",
    "coronal_train_loader = torch.utils.data.DataLoader(coronal_train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "coronal_val_dataset = MRDataset(root_dir='', task='acl', plane='coronal', transform=augmentor, train=False)\n",
    "coronal_val_loader = torch.utils.data.DataLoader(coronal_val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25, 3, 256, 256]) torch.Size([1, 2]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "for i, (image, label, weight) in enumerate(coronal_val_loader):\n",
    "    if i == 0:\n",
    "        print(image.size(), label.size(), weight.size())\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coronal_mrnet = MRNet()\n",
    "if torch.cuda.is_available():\n",
    "    coronal_mrnet.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(coronal_mrnet.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = float(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.1595 | train auc : 0.7798 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.9981 | train auc : 0.8283 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0506 | train auc : 0.8239 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0607 | train auc : 0.8244 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0355 | train auc : 0.8206 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 600 / 1130 | avg train loss : 0.9806 | train auc : 0.8304 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.005 | train auc : 0.8213 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.001 | train auc : 0.8266 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.0289 | train auc : 0.8123 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0206 | train auc : 0.8126 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.0271 | train auc : 0.8117 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 20 / 120 | avg val loss : 0.3521 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 40 / 120 | avg val loss : 0.3362 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 60 / 120 | avg val loss : 0.517 | val auc : 0.8168 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 80 / 120 | avg val loss : 0.6131 | val auc : 0.836 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 100 / 120 | avg val loss : 0.6649 | val auc : 0.8133 | lr : 1e-05\n",
      "train loss : 1.0371 | train auc 0.8081 | val loss 0.6403 | val auc 0.8086 | elapsed time 667.1024990081787 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.2368 | train auc : 0.7411 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.1178 | train auc : 0.8178 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0236 | train auc : 0.8191 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.9812 | train auc : 0.8323 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9787 | train auc : 0.8308 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0102 | train auc : 0.8082 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.9953 | train auc : 0.8113 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0224 | train auc : 0.8106 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.0127 | train auc : 0.8176 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0152 | train auc : 0.8192 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.023 | train auc : 0.8213 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 20 / 120 | avg val loss : 0.166 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1602 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 60 / 120 | avg val loss : 0.5577 | val auc : 0.8275 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 80 / 120 | avg val loss : 0.7676 | val auc : 0.8483 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8514 | val auc : 0.8157 | lr : 1e-05\n",
      "train loss : 1.0132 | train auc 0.821 | val loss 0.7965 | val auc 0.8114 | elapsed time 695.0390684604645 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.9928 | train auc : 0.83 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.9844 | train auc : 0.8273 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0077 | train auc : 0.8008 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.9787 | train auc : 0.8086 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9814 | train auc : 0.8101 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 600 / 1130 | avg train loss : 0.9858 | train auc : 0.8035 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.966 | train auc : 0.8181 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 800 / 1130 | avg train loss : 0.9549 | train auc : 0.8263 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 900 / 1130 | avg train loss : 0.9639 | train auc : 0.8331 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1000 / 1130 | avg train loss : 0.9684 | train auc : 0.8326 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1100 / 1130 | avg train loss : 0.9906 | train auc : 0.8302 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1516 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1493 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 60 / 120 | avg val loss : 0.5418 | val auc : 0.8289 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 80 / 120 | avg val loss : 0.7269 | val auc : 0.8673 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8199 | val auc : 0.8275 | lr : 1e-05\n",
      "train loss : 0.9908 | train auc 0.8304 | val loss 0.7692 | val auc 0.8213 | elapsed time 689.0459628105164 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.6892 | train auc : 0.9403 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0316 | train auc : 0.8289 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 300 / 1130 | avg train loss : 0.9988 | train auc : 0.8338 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0021 | train auc : 0.8321 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9517 | train auc : 0.8393 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 600 / 1130 | avg train loss : 0.9891 | train auc : 0.8494 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.9795 | train auc : 0.8554 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 800 / 1130 | avg train loss : 0.9802 | train auc : 0.8591 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 900 / 1130 | avg train loss : 0.9625 | train auc : 0.8608 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1000 / 1130 | avg train loss : 0.9501 | train auc : 0.8615 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1100 / 1130 | avg train loss : 0.9435 | train auc : 0.8635 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1057 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 40 / 120 | avg val loss : 0.0907 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6412 | val auc : 0.8516 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 80 / 120 | avg val loss : 0.8929 | val auc : 0.8771 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 100 / 120 | avg val loss : 1.028 | val auc : 0.8169 | lr : 1e-05\n",
      "train loss : 0.9302 | train auc 0.8656 | val loss 0.9405 | val auc 0.8199 | elapsed time 682.5841166973114 s\n",
      "------------------------------\n",
      "Epoch: 5 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.9544 | train auc : 0.8206 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.8298 | train auc : 0.8584 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 300 / 1130 | avg train loss : 0.8422 | train auc : 0.8398 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.9783 | train auc : 0.82 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9601 | train auc : 0.8316 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 600 / 1130 | avg train loss : 0.9624 | train auc : 0.8418 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.9806 | train auc : 0.8316 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 800 / 1130 | avg train loss : 0.9761 | train auc : 0.8299 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 900 / 1130 | avg train loss : 0.9753 | train auc : 0.8328 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1000 / 1130 | avg train loss : 0.9741 | train auc : 0.8323 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1100 / 1130 | avg train loss : 0.9595 | train auc : 0.8414 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1901 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1901 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 60 / 120 | avg val loss : 0.4855 | val auc : 0.8516 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 80 / 120 | avg val loss : 0.6409 | val auc : 0.8716 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 100 / 120 | avg val loss : 0.7242 | val auc : 0.838 | lr : 1e-05\n",
      "Epoch     5: reducing learning rate of group 0 to 3.0000e-06.\n",
      "train loss : 0.9721 | train auc 0.838 | val loss 0.674 | val auc 0.844 | elapsed time 682.4214630126953 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.6581 | train auc : 0.9157 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.7785 | train auc : 0.8805 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 300 / 1130 | avg train loss : 0.8205 | train auc : 0.8716 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.8609 | train auc : 0.8664 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.8438 | train auc : 0.8829 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 600 / 1130 | avg train loss : 0.8715 | train auc : 0.8767 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.8759 | train auc : 0.8771 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 800 / 1130 | avg train loss : 0.8778 | train auc : 0.8788 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 900 / 1130 | avg train loss : 0.9033 | train auc : 0.8749 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 1000 / 1130 | avg train loss : 0.8919 | train auc : 0.8777 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 1100 / 1130 | avg train loss : 0.8721 | train auc : 0.8804 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1326 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1239 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 60 / 120 | avg val loss : 0.519 | val auc : 0.8422 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 80 / 120 | avg val loss : 0.712 | val auc : 0.8716 | lr : 3e-06\n",
      "Epoch: 6 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8152 | val auc : 0.8416 | lr : 3e-06\n",
      "train loss : 0.8738 | train auc 0.88 | val loss 0.7539 | val auc 0.8468 | elapsed time 717.7134411334991 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 5 iterations without the decrease of the val loss\n",
      "Training took 4142.865465164185 s\n"
     ]
    }
   ],
   "source": [
    "# coronal_mrnet = MRNet()\n",
    "# if torch.cuda.is_available():\n",
    "#     coronal_mrnet.cuda()\n",
    "\n",
    "# optimizer = torch.optim.Adam(coronal_mrnet.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "\n",
    "# best_val_loss = float('inf')\n",
    "# best_val_acc = float(0)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "iteration_change_loss = 0\n",
    "t_start_training = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_model(model=coronal_mrnet, train_loader=coronal_train_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, optimizer=optimizer, current_lr=current_lr)\n",
    "    val_loss, val_acc = evaluate_model(model=coronal_mrnet, valid_loader=coronal_val_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, current_lr=current_lr)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    t_end = time.time()\n",
    "    delta = t_end - t_start\n",
    "    print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
    "            train_loss, train_acc, val_loss, val_acc, delta))\n",
    "\n",
    "    iteration_change_loss += 1\n",
    "    print('-' * 30)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        file_name = 'coronal_best.pth'\n",
    "        torch.save(coronal_mrnet, file_name)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        iteration_change_loss = 0\n",
    "        \n",
    "    if iteration_change_loss == 5:\n",
    "        print('Early stopping after {0} iterations without the decrease of the val loss'.\n",
    "              format(iteration_change_loss))\n",
    "        break\n",
    "        \n",
    "t_end_training = time.time()\n",
    "print('Training took {} s'.format(t_end_training - t_start_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = Compose([\n",
    "        transforms.Lambda(lambda x: torch.Tensor(x)),\n",
    "        RandomRotate(25),\n",
    "        RandomTranslate([0.11, 0.11]),\n",
    "        RandomFlip(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1, 1).permute(1, 0, 2, 3)),\n",
    "    ])\n",
    "\n",
    "axial_train_dataset = MRDataset(root_dir='', task='acl', plane='axial', transform=augmentor, train=True)\n",
    "axial_train_loader = torch.utils.data.DataLoader(axial_train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "axial_val_dataset = MRDataset(root_dir='', task='acl', plane='axial', transform=augmentor, train=False)\n",
    "axial_val_loader = torch.utils.data.DataLoader(axial_val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "axial_mrnet = MRNet()\n",
    "if torch.cuda.is_available():\n",
    "    axial_mrnet.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(axial_mrnet.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = float(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 50 | Single batch number : 100 / 1130 | avg train loss : 4.3027 | train auc : 0.3882 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 200 / 1130 | avg train loss : 3.6715 | train auc : 0.4519 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 300 / 1130 | avg train loss : 3.5081 | train auc : 0.5104 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 400 / 1130 | avg train loss : 3.3185 | train auc : 0.5299 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 500 / 1130 | avg train loss : 2.9846 | train auc : 0.5463 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 600 / 1130 | avg train loss : 2.8303 | train auc : 0.5429 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 700 / 1130 | avg train loss : 2.659 | train auc : 0.5539 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 800 / 1130 | avg train loss : 2.4993 | train auc : 0.571 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 900 / 1130 | avg train loss : 2.3824 | train auc : 0.5719 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1000 / 1130 | avg train loss : 2.2862 | train auc : 0.5847 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1100 / 1130 | avg train loss : 2.1962 | train auc : 0.5932 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1855 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 40 / 120 | avg val loss : 0.2103 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 60 / 120 | avg val loss : 0.7574 | val auc : 0.7767 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 80 / 120 | avg val loss : 0.9897 | val auc : 0.8163 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 100 / 120 | avg val loss : 1.0709 | val auc : 0.7812 | lr : 1e-05\n",
      "train loss : 2.1548 | train auc 0.5941 | val loss 1.0567 | val auc 0.7396 | elapsed time 847.1651556491852 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.4547 | train auc : 0.6767 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.6555 | train auc : 0.635 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.556 | train auc : 0.6339 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.4707 | train auc : 0.6664 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.3719 | train auc : 0.6788 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.3701 | train auc : 0.6829 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.3557 | train auc : 0.6848 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.3215 | train auc : 0.6926 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.3182 | train auc : 0.6943 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.3424 | train auc : 0.6981 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.3502 | train auc : 0.6944 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1305 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1277 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 60 / 120 | avg val loss : 0.7137 | val auc : 0.7246 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 80 / 120 | avg val loss : 0.9395 | val auc : 0.7973 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 100 / 120 | avg val loss : 1.0444 | val auc : 0.771 | lr : 1e-05\n",
      "train loss : 1.3501 | train auc 0.6948 | val loss 1.0273 | val auc 0.7284 | elapsed time 817.7875273227692 s\n",
      "------------------------------\n",
      "Epoch: 3 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.4285 | train auc : 0.679 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.4387 | train auc : 0.6739 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.2726 | train auc : 0.7004 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.214 | train auc : 0.7071 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.2648 | train auc : 0.7025 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.2376 | train auc : 0.7022 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.2508 | train auc : 0.6973 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.2305 | train auc : 0.6967 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.2579 | train auc : 0.7 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.2457 | train auc : 0.6974 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.252 | train auc : 0.7055 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1756 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1789 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6138 | val auc : 0.7473 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 80 / 120 | avg val loss : 0.7724 | val auc : 0.8028 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 100 / 120 | avg val loss : 0.878 | val auc : 0.7714 | lr : 1e-05\n",
      "train loss : 1.2589 | train auc 0.7071 | val loss 0.8891 | val auc 0.727 | elapsed time 944.7222483158112 s\n",
      "------------------------------\n",
      "Epoch: 4 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.1648 | train auc : 0.7998 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0801 | train auc : 0.7657 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.1249 | train auc : 0.7663 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.2314 | train auc : 0.7574 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.2029 | train auc : 0.7477 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.199 | train auc : 0.7251 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.1877 | train auc : 0.7311 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.1898 | train auc : 0.728 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.1845 | train auc : 0.7352 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.1981 | train auc : 0.7255 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.2227 | train auc : 0.7275 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0748 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 40 / 120 | avg val loss : 0.0838 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6869 | val auc : 0.7727 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 80 / 120 | avg val loss : 0.9908 | val auc : 0.8047 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 100 / 120 | avg val loss : 1.153 | val auc : 0.7467 | lr : 1e-05\n",
      "train loss : 1.208 | train auc 0.7297 | val loss 1.1025 | val auc 0.7012 | elapsed time 983.1358666419983 s\n",
      "------------------------------\n",
      "Epoch: 5 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.9588 | train auc : 0.7868 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0753 | train auc : 0.7127 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0015 | train auc : 0.7449 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0654 | train auc : 0.7705 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0954 | train auc : 0.749 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.109 | train auc : 0.751 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.1361 | train auc : 0.742 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.1326 | train auc : 0.7376 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.1516 | train auc : 0.7305 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.1495 | train auc : 0.736 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1407 | train auc : 0.7402 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1036 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1147 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6588 | val auc : 0.8061 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 80 / 120 | avg val loss : 0.9322 | val auc : 0.8409 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 100 / 120 | avg val loss : 1.1035 | val auc : 0.7894 | lr : 1e-05\n",
      "train loss : 1.1537 | train auc 0.7368 | val loss 1.0598 | val auc 0.7489 | elapsed time 892.9718420505524 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.254 | train auc : 0.7795 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.1802 | train auc : 0.8055 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.1185 | train auc : 0.806 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0866 | train auc : 0.7993 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0565 | train auc : 0.8006 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0421 | train auc : 0.8035 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0556 | train auc : 0.793 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0633 | train auc : 0.7845 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.09 | train auc : 0.7719 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0788 | train auc : 0.7727 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1151 | train auc : 0.7632 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0865 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1032 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 60 / 120 | avg val loss : 0.5953 | val auc : 0.8356 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 80 / 120 | avg val loss : 0.8861 | val auc : 0.8421 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 100 / 120 | avg val loss : 1.0734 | val auc : 0.7855 | lr : 1e-05\n",
      "train loss : 1.104 | train auc 0.7658 | val loss 1.0261 | val auc 0.7618 | elapsed time 872.4203193187714 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.0449 | train auc : 0.7697 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.9898 | train auc : 0.7664 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0778 | train auc : 0.7653 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0546 | train auc : 0.7866 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0529 | train auc : 0.7914 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0709 | train auc : 0.7896 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0761 | train auc : 0.7887 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0962 | train auc : 0.7871 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.0702 | train auc : 0.7861 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0797 | train auc : 0.7818 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.098 | train auc : 0.7728 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0764 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 40 / 120 | avg val loss : 0.0864 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6227 | val auc : 0.8235 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 80 / 120 | avg val loss : 0.9068 | val auc : 0.8624 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 100 / 120 | avg val loss : 1.0677 | val auc : 0.8078 | lr : 1e-05\n",
      "Epoch     7: reducing learning rate of group 0 to 3.0000e-06.\n",
      "train loss : 1.0958 | train auc 0.7743 | val loss 1.0163 | val auc 0.7806 | elapsed time 843.5210158824921 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.8775 | train auc : 0.8424 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 200 / 1130 | avg train loss : 0.9218 | train auc : 0.854 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 300 / 1130 | avg train loss : 0.9806 | train auc : 0.8342 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.9935 | train auc : 0.8246 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9858 | train auc : 0.8234 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.025 | train auc : 0.8167 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 700 / 1130 | avg train loss : 0.9928 | train auc : 0.8305 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.04 | train auc : 0.8253 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.024 | train auc : 0.8256 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0138 | train auc : 0.8263 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.0232 | train auc : 0.8185 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0558 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 40 / 120 | avg val loss : 0.072 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6589 | val auc : 0.8249 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 80 / 120 | avg val loss : 0.94 | val auc : 0.8778 | lr : 3e-06\n",
      "Epoch: 8 / 50 | Single batch number : 100 / 120 | avg val loss : 1.1258 | val auc : 0.8392 | lr : 3e-06\n",
      "train loss : 1.0189 | train auc 0.8206 | val loss 1.0674 | val auc 0.8182 | elapsed time 796.9701690673828 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 5 iterations without the decrease of the val loss\n",
      "Training took 7006.245965003967 s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "iteration_change_loss = 0\n",
    "t_start_training = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_model(model=axial_mrnet, train_loader=axial_train_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, optimizer=optimizer, current_lr=current_lr)\n",
    "    val_loss, val_acc = evaluate_model(model=axial_mrnet, valid_loader=axial_val_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, current_lr=current_lr)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    t_end = time.time()\n",
    "    delta = t_end - t_start\n",
    "    print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
    "            train_loss, train_acc, val_loss, val_acc, delta))\n",
    "\n",
    "    iteration_change_loss += 1\n",
    "    print('-' * 30)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        file_name = 'axial_best.pth'\n",
    "        torch.save(axial_mrnet, file_name)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        iteration_change_loss = 0\n",
    "        \n",
    "    if iteration_change_loss == 5:\n",
    "        print('Early stopping after {0} iterations without the decrease of the val loss'.\n",
    "              format(iteration_change_loss))\n",
    "        break\n",
    "        \n",
    "t_end_training = time.time()\n",
    "print('Training took {} s'.format(t_end_training - t_start_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Sagittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = Compose([\n",
    "        transforms.Lambda(lambda x: torch.Tensor(x)),\n",
    "        RandomRotate(25),\n",
    "        RandomTranslate([0.11, 0.11]),\n",
    "        RandomFlip(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1, 1).permute(1, 0, 2, 3)),\n",
    "    ])\n",
    "\n",
    "sagittal_train_dataset = MRDataset(root_dir='', task='acl', plane='sagittal', transform=augmentor, train=True)\n",
    "sagittal_train_loader = torch.utils.data.DataLoader(sagittal_train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "sagittal_val_dataset = MRDataset(root_dir='', task='acl', plane='sagittal', transform=augmentor, train=False)\n",
    "sagittal_val_loader = torch.utils.data.DataLoader(sagittal_val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "sagittal_mrnet = MRNet()\n",
    "if torch.cuda.is_available():\n",
    "    sagittal_mrnet.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(sagittal_mrnet.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = float(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 50 | Single batch number : 100 / 1130 | avg train loss : 6.3007 | train auc : 0.4275 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 200 / 1130 | avg train loss : 4.4658 | train auc : 0.4677 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 300 / 1130 | avg train loss : 4.0244 | train auc : 0.4909 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 400 / 1130 | avg train loss : 3.5293 | train auc : 0.5045 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 500 / 1130 | avg train loss : 3.2177 | train auc : 0.5172 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 600 / 1130 | avg train loss : 2.9455 | train auc : 0.5403 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 700 / 1130 | avg train loss : 2.7955 | train auc : 0.558 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 800 / 1130 | avg train loss : 2.6942 | train auc : 0.5765 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 900 / 1130 | avg train loss : 2.555 | train auc : 0.5778 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1000 / 1130 | avg train loss : 2.4705 | train auc : 0.5776 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 1100 / 1130 | avg train loss : 2.4278 | train auc : 0.5746 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 20 / 120 | avg val loss : 0.8158 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 40 / 120 | avg val loss : 0.746 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 60 / 120 | avg val loss : 1.1608 | val auc : 0.6297 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 80 / 120 | avg val loss : 1.4078 | val auc : 0.6345 | lr : 1e-05\n",
      "Epoch: 1 / 50 | Single batch number : 100 / 120 | avg val loss : 1.5194 | val auc : 0.589 | lr : 1e-05\n",
      "train loss : 2.4081 | train auc 0.5743 | val loss 1.4265 | val auc 0.5727 | elapsed time 746.232373714447 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.1558 | train auc : 0.6723 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.2041 | train auc : 0.6816 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.388 | train auc : 0.674 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.48 | train auc : 0.6627 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.422 | train auc : 0.6623 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.416 | train auc : 0.649 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.4022 | train auc : 0.6452 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.4221 | train auc : 0.6335 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.3881 | train auc : 0.6323 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.4121 | train auc : 0.64 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.4433 | train auc : 0.6371 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 20 / 120 | avg val loss : 0.4158 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 40 / 120 | avg val loss : 0.3501 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 60 / 120 | avg val loss : 0.632 | val auc : 0.746 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 80 / 120 | avg val loss : 0.7799 | val auc : 0.7518 | lr : 1e-05\n",
      "Epoch: 2 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8795 | val auc : 0.7133 | lr : 1e-05\n",
      "train loss : 1.4459 | train auc 0.6354 | val loss 0.8611 | val auc 0.6888 | elapsed time 693.5728535652161 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.2606 | train auc : 0.5801 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.2594 | train auc : 0.7222 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.2974 | train auc : 0.6871 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.2997 | train auc : 0.6941 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.3125 | train auc : 0.6901 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.3024 | train auc : 0.6834 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.3488 | train auc : 0.6692 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.3401 | train auc : 0.6691 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.3421 | train auc : 0.6585 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.3197 | train auc : 0.6592 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.3181 | train auc : 0.6701 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1838 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1475 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 60 / 120 | avg val loss : 0.6872 | val auc : 0.7995 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 80 / 120 | avg val loss : 1.0075 | val auc : 0.8065 | lr : 1e-05\n",
      "Epoch: 3 / 50 | Single batch number : 100 / 120 | avg val loss : 1.1985 | val auc : 0.7514 | lr : 1e-05\n",
      "train loss : 1.3193 | train auc 0.6687 | val loss 1.1344 | val auc 0.7281 | elapsed time 711.9149317741394 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.2513 | train auc : 0.7798 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.4916 | train auc : 0.7157 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.4026 | train auc : 0.7156 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.4043 | train auc : 0.7061 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.401 | train auc : 0.6905 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.3573 | train auc : 0.6943 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.3424 | train auc : 0.69 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.3098 | train auc : 0.6912 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.3 | train auc : 0.6904 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.3031 | train auc : 0.6798 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.3006 | train auc : 0.6862 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0823 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 40 / 120 | avg val loss : 0.0766 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 60 / 120 | avg val loss : 0.7674 | val auc : 0.8275 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 80 / 120 | avg val loss : 1.2291 | val auc : 0.8317 | lr : 1e-05\n",
      "Epoch: 4 / 50 | Single batch number : 100 / 120 | avg val loss : 1.4633 | val auc : 0.7792 | lr : 1e-05\n",
      "train loss : 1.2832 | train auc 0.6894 | val loss 1.373 | val auc 0.7489 | elapsed time 790.5976278781891 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.0397 | train auc : 0.6364 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.1864 | train auc : 0.7404 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.1945 | train auc : 0.7563 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.2673 | train auc : 0.7484 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.2412 | train auc : 0.7499 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.2245 | train auc : 0.7393 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.1737 | train auc : 0.7289 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.1778 | train auc : 0.7202 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.1494 | train auc : 0.7248 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.1868 | train auc : 0.7198 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1968 | train auc : 0.7279 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1109 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1177 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 60 / 120 | avg val loss : 0.518 | val auc : 0.8342 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 80 / 120 | avg val loss : 0.739 | val auc : 0.8593 | lr : 1e-05\n",
      "Epoch: 5 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8949 | val auc : 0.8243 | lr : 1e-05\n",
      "train loss : 1.1937 | train auc 0.7304 | val loss 0.8761 | val auc 0.7966 | elapsed time 867.2921957969666 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.3529 | train auc : 0.697 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.2471 | train auc : 0.7368 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.1167 | train auc : 0.7686 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.1413 | train auc : 0.7506 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.1814 | train auc : 0.7374 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.1947 | train auc : 0.7392 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.1452 | train auc : 0.7477 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.1762 | train auc : 0.7456 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.2253 | train auc : 0.7295 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.2044 | train auc : 0.7267 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1757 | train auc : 0.7362 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1121 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1297 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 60 / 120 | avg val loss : 0.4654 | val auc : 0.8476 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 80 / 120 | avg val loss : 0.6343 | val auc : 0.8821 | lr : 1e-05\n",
      "Epoch: 6 / 50 | Single batch number : 100 / 120 | avg val loss : 0.7731 | val auc : 0.8365 | lr : 1e-05\n",
      "train loss : 1.1742 | train auc 0.7368 | val loss 0.7606 | val auc 0.8162 | elapsed time 848.2521739006042 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.0925 | train auc : 0.8604 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.1609 | train auc : 0.8107 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.2283 | train auc : 0.7843 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.1718 | train auc : 0.779 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.2066 | train auc : 0.7781 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.2218 | train auc : 0.7631 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.1674 | train auc : 0.7737 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.1715 | train auc : 0.763 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.1287 | train auc : 0.7737 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.1189 | train auc : 0.7709 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1165 | train auc : 0.773 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0942 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1171 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 60 / 120 | avg val loss : 0.4824 | val auc : 0.8717 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 80 / 120 | avg val loss : 0.6755 | val auc : 0.9036 | lr : 1e-05\n",
      "Epoch: 7 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8258 | val auc : 0.8471 | lr : 1e-05\n",
      "train loss : 1.1204 | train auc 0.7668 | val loss 0.8119 | val auc 0.8176 | elapsed time 831.6071202754974 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 50 | Single batch number : 100 / 1130 | avg train loss : 0.9526 | train auc : 0.7308 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0167 | train auc : 0.7749 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0199 | train auc : 0.7758 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0107 | train auc : 0.7869 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0459 | train auc : 0.7729 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0314 | train auc : 0.7689 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0904 | train auc : 0.7629 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0691 | train auc : 0.7709 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.0853 | train auc : 0.7617 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0987 | train auc : 0.7557 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1036 | train auc : 0.763 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0565 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 40 / 120 | avg val loss : 0.081 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 60 / 120 | avg val loss : 0.545 | val auc : 0.9144 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 80 / 120 | avg val loss : 0.801 | val auc : 0.9269 | lr : 1e-05\n",
      "Epoch: 8 / 50 | Single batch number : 100 / 120 | avg val loss : 0.9814 | val auc : 0.8827 | lr : 1e-05\n",
      "train loss : 1.0996 | train auc 0.7643 | val loss 0.984 | val auc 0.8333 | elapsed time 880.3588767051697 s\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorchLab\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MRNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.1174 | train auc : 0.829 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.048 | train auc : 0.7782 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0328 | train auc : 0.7769 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 400 / 1130 | avg train loss : 0.9881 | train auc : 0.7902 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 500 / 1130 | avg train loss : 0.9882 | train auc : 0.7783 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0592 | train auc : 0.7622 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0891 | train auc : 0.7478 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0791 | train auc : 0.7491 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.104 | train auc : 0.7451 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.1104 | train auc : 0.7399 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.1311 | train auc : 0.7322 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 20 / 120 | avg val loss : 0.1369 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1523 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 60 / 120 | avg val loss : 0.5168 | val auc : 0.865 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 80 / 120 | avg val loss : 0.733 | val auc : 0.8821 | lr : 1e-05\n",
      "Epoch: 9 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8554 | val auc : 0.8361 | lr : 1e-05\n",
      "train loss : 1.1352 | train auc 0.7338 | val loss 0.8353 | val auc 0.8013 | elapsed time 880.0091211795807 s\n",
      "------------------------------\n",
      "Epoch: 10 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.0396 | train auc : 0.7302 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0175 | train auc : 0.7312 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 300 / 1130 | avg train loss : 0.9966 | train auc : 0.7992 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.1072 | train auc : 0.7674 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0603 | train auc : 0.7836 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0564 | train auc : 0.7727 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0682 | train auc : 0.776 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 800 / 1130 | avg train loss : 1.0743 | train auc : 0.7731 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 900 / 1130 | avg train loss : 1.0812 | train auc : 0.7678 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0929 | train auc : 0.7721 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.0703 | train auc : 0.7759 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0843 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 40 / 120 | avg val loss : 0.101 | val auc : 0.5 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 60 / 120 | avg val loss : 0.5163 | val auc : 0.8342 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 80 / 120 | avg val loss : 0.7431 | val auc : 0.871 | lr : 1e-05\n",
      "Epoch: 10 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8756 | val auc : 0.831 | lr : 1e-05\n",
      "Epoch    10: reducing learning rate of group 0 to 3.0000e-06.\n",
      "train loss : 1.0759 | train auc 0.7753 | val loss 0.8464 | val auc 0.8185 | elapsed time 837.2938594818115 s\n",
      "------------------------------\n",
      "Epoch: 11 / 50 | Single batch number : 100 / 1130 | avg train loss : 1.08 | train auc : 0.7517 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 200 / 1130 | avg train loss : 1.0324 | train auc : 0.7682 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 300 / 1130 | avg train loss : 1.0748 | train auc : 0.8144 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 400 / 1130 | avg train loss : 1.0614 | train auc : 0.8125 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 500 / 1130 | avg train loss : 1.0987 | train auc : 0.7913 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 600 / 1130 | avg train loss : 1.0246 | train auc : 0.7968 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 700 / 1130 | avg train loss : 1.0167 | train auc : 0.794 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 800 / 1130 | avg train loss : 0.9795 | train auc : 0.8027 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 900 / 1130 | avg train loss : 0.9852 | train auc : 0.8079 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 1000 / 1130 | avg train loss : 1.0067 | train auc : 0.8029 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 1100 / 1130 | avg train loss : 1.0221 | train auc : 0.803 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 20 / 120 | avg val loss : 0.0916 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 40 / 120 | avg val loss : 0.1126 | val auc : 0.5 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 60 / 120 | avg val loss : 0.4892 | val auc : 0.8516 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 80 / 120 | avg val loss : 0.6683 | val auc : 0.8962 | lr : 3e-06\n",
      "Epoch: 11 / 50 | Single batch number : 100 / 120 | avg val loss : 0.8168 | val auc : 0.8439 | lr : 3e-06\n",
      "train loss : 1.0231 | train auc 0.8035 | val loss 0.7989 | val auc 0.8277 | elapsed time 834.4319767951965 s\n",
      "------------------------------\n",
      "Early stopping after 5 iterations without the decrease of the val loss\n",
      "Training took 8933.763492107391 s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "iteration_change_loss = 0\n",
    "t_start_training = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_model(model=sagittal_mrnet, train_loader=sagittal_train_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, optimizer=optimizer, current_lr=current_lr)\n",
    "    val_loss, val_acc = evaluate_model(model=sagittal_mrnet, valid_loader=sagittal_val_loader,\n",
    "                                       epoch=epoch, num_epochs=NUM_EPOCHS, current_lr=current_lr)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    t_end = time.time()\n",
    "    delta = t_end - t_start\n",
    "    print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
    "            train_loss, train_acc, val_loss, val_acc, delta))\n",
    "\n",
    "    iteration_change_loss += 1\n",
    "    print('-' * 30)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        file_name = 'sagittal_best.pth'\n",
    "        torch.save(sagittal_mrnet, file_name)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        iteration_change_loss = 0\n",
    "        \n",
    "    if iteration_change_loss == 5:\n",
    "        print('Early stopping after {0} iterations without the decrease of the val loss'.\n",
    "              format(iteration_change_loss))\n",
    "        break\n",
    "        \n",
    "t_end_training = time.time()\n",
    "print('Training took {} s'.format(t_end_training - t_start_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
